@using TelegramGroupsAdmin.ContentDetection.Configuration
@using TelegramGroupsAdmin.ContentDetection.Models
@using TelegramGroupsAdmin.ContentDetection.Repositories
@using TelegramGroupsAdmin.Services
@inject IContentDetectionConfigRepository ConfigRepository
@inject IPromptVersionRepository PromptVersionRepository
@inject IDialogService DialogService
@inject ISnackbar Snackbar
@inject BlazorAuthHelper AuthHelper

<MudPaper Class="pa-4" Elevation="1">
    <MudStack Spacing="3">
        <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="1">
            <MudText Typo="Typo.h6" Color="Color.Primary">OpenAI Integration</MudText>
            <HelpTooltip Text="Uses GPT-4 to analyze message context and intent. Best accuracy for nuanced spam detection. Two modes: Veto Mode (confirms other algorithms' detections) or Detection Mode (actively searches for spam). Slow (~1.2s avg) but high quality." />
        </MudStack>

        @if (!IsGlobalView)
        {
            <MudPaper Class="pa-3" Elevation="0" Style="background-color: var(--mud-palette-background-grey)">
                <MudSwitch T="bool" @bind-Value="_config.OpenAI.UseGlobal"
                          Label="@(_config.OpenAI.UseGlobal ? "Using Global Settings" : "Using Custom Settings")"
                          Color="@(_config.OpenAI.UseGlobal ? Color.Default : Color.Primary)" />
            </MudPaper>
        }

        @{
            var openAiConfig = (IsGlobalView || !_config.OpenAI.UseGlobal) ? _config.OpenAI : _globalConfig.OpenAI;
            var openAiReadOnly = !IsGlobalView && _config.OpenAI.UseGlobal;
        }

        <MudSwitch T="bool" @bind-Value="openAiConfig.Enabled"
                  Label="Enable OpenAI Check"
                  Color="Color.Primary"
                  Disabled="@openAiReadOnly" />

        @if (openAiConfig.Enabled)
        {
            <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="1">
                <MudSwitch T="bool" @bind-Value="openAiConfig.VetoMode"
                          Label="Veto Mode (Confirm Spam)"
                          Color="Color.Primary"
                          Disabled="@openAiReadOnly" />
                <HelpTooltip Text="Veto Mode ON: OpenAI reviews other algorithms' detections and can override false positives (reduces false positives, recommended). Veto Mode OFF: OpenAI actively searches for spam and contributes to confidence voting (more aggressive, higher costs)." />
            </MudStack>

            <ConceptualAlert Severity="@(openAiConfig.VetoMode ? Severity.Success : Severity.Warning)" Dense="true">
                @if (openAiConfig.VetoMode)
                {
                    <text>
                        <strong>Veto Mode Enabled:</strong> OpenAI acts as quality control. Other algorithms flag spam, OpenAI confirms or vetoes.
                        Reduces false positives while keeping costs lower (only runs on suspicious messages).
                    </text>
                }
                else
                {
                    <text>
                        <strong>Detection Mode:</strong> OpenAI actively searches for spam on every message.
                        Higher accuracy but significantly higher API costs. Consider enabling only for high-risk communities.
                    </text>
                }
            </ConceptualAlert>

            @if (openAiConfig.VetoMode)
            {
                <FieldWithHelp HelpText="OpenAI veto check runs only when other algorithms' combined confidence is BELOW this threshold. Set to 100 to always run veto checks. Set to 85 to skip veto on high-confidence detections (saves API calls).">
                    <MudNumericField @bind-Value="openAiConfig.VetoThreshold"
                                    Label="Veto Threshold"
                                    Min="50" Max="100"
                                    Disabled="@openAiReadOnly"
                                    HelperText="@(openAiReadOnly ? $"Using global value: {openAiConfig.VetoThreshold}" : "OpenAI veto runs only if spam confidence is below this (higher = more vetos)")" />
                </FieldWithHelp>
            }

            <MudSwitch T="bool" @bind-Value="openAiConfig.CheckShortMessages"
                      Label="Check Short Messages"
                      Color="Color.Primary"
                      Disabled="@openAiReadOnly" />

            <FieldWithHelp HelpText="Number of recent messages to include as context for OpenAI analysis. Higher values provide more conversation context but increase API costs. 0 = no history, 3-5 recommended for most groups.">
                <MudNumericField @bind-Value="openAiConfig.MessageHistoryCount"
                                Label="Message History Count"
                                Min="0" Max="10"
                                Disabled="@openAiReadOnly"
                                HelperText="@(openAiReadOnly ? $"Using global value: {openAiConfig.MessageHistoryCount}" : "Recent messages sent to OpenAI for context (0-10)")" />
            </FieldWithHelp>

            <MudTextField @bind-Value="openAiConfig.SystemPrompt"
                         Label="Custom System Prompt (Optional)"
                         Lines="5"
                         AutoGrow="true"
                         Variant="Variant.Outlined"
                         Disabled="@openAiReadOnly"
                         HelperText="@(openAiReadOnly ? "Using global prompt" : "Topic-specific instructions for this group")" />

            <MudNumericField @bind-Value="openAiConfig.ConfidenceThreshold"
                            Label="Confidence Threshold"
                            Min="1" Max="100"
                            Disabled="@openAiReadOnly"
                            HelperText="@(openAiReadOnly ? $"Using global value: {openAiConfig.ConfidenceThreshold}" : "Confidence level for OpenAI spam classification")" />

            @* AI Prompt Builder - NOW AVAILABLE FOR BOTH GLOBAL AND PER-CHAT *@
            @if (!openAiReadOnly)
            {
                <MudDivider Class="my-2" />
                <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="2">
                    <MudText Typo="Typo.subtitle1" Color="Color.Primary">AI Prompt Builder</MudText>
                    <MudSpacer />
                    <MudButton Color="Color.Primary"
                              Variant="Variant.Filled"
                              Size="Size.Small"
                              StartIcon="@Icons.Material.Filled.AutoAwesome"
                              OnClick="@OpenPromptBuilder">
                        Generate with AI
                    </MudButton>
                </MudStack>

                @if (_promptVersions.Any())
                {
                    <MudText Typo="Typo.body2" Class="mud-text-secondary">
                        Version History (@_promptVersions.Count versions)
                    </MudText>

                    <MudList T="string" Dense="true">
                        @foreach (var version in _promptVersions.Take(5))
                        {
                            <MudListItem T="string">
                                <MudStack Row="true" AlignItems="AlignItems.Center" Spacing="1">
                                    <MudChip T="string"
                                            Size="Size.Small"
                                            Color="@(version.IsActive ? Color.Success : Color.Default)"
                                            Variant="@(version.IsActive ? Variant.Filled : Variant.Outlined)">
                                        v@(version.Version)
                                    </MudChip>
                                    <MudText Typo="Typo.caption" Class="flex-grow-1">
                                        @version.CreatedAt.ToLocalTime().ToString("MMM d, yyyy h:mm tt")
                                        @if (!string.IsNullOrEmpty(version.CreatedBy))
                                        {
                                            <text> by @version.CreatedBy</text>
                                        }
                                    </MudText>
                                    @if (!version.IsActive)
                                    {
                                        <MudIconButton Icon="@Icons.Material.Filled.RestorePage"
                                                      Size="Size.Small"
                                                      Color="Color.Primary"
                                                      OnClick="@(() => RestoreVersion(version.Id))"
                                                      title="Restore this version" />
                                    }
                                    <MudIconButton Icon="@Icons.Material.Filled.AutoFixHigh"
                                                  Size="Size.Small"
                                                  Color="Color.Secondary"
                                                  OnClick="@(() => OpenImproveDialog(version))"
                                                  title="Improve with AI" />
                                    <MudIconButton Icon="@Icons.Material.Filled.Visibility"
                                                  Size="Size.Small"
                                                  Color="Color.Default"
                                                  OnClick="@(() => ViewVersion(version))"
                                                  title="View prompt" />
                                </MudStack>
                            </MudListItem>
                        }
                    </MudList>

                    @if (_promptVersions.Count > 5)
                    {
                        <MudText Typo="Typo.caption" Class="mud-text-secondary">
                            Showing 5 of @_promptVersions.Count versions
                        </MudText>
                    }
                }
            }
        }
    </MudStack>
</MudPaper>

@code {
    [Parameter]
    public long? ChatId { get; set; }

    private ContentDetectionConfig _config = new();
    private ContentDetectionConfig _globalConfig = new();
    private List<PromptVersion> _promptVersions = [];
    private bool IsGlobalView => ChatId is null or 0;

    protected override async Task OnInitializedAsync()
    {
        await LoadConfiguration();
        await LoadPromptVersions();
    }

    private async Task LoadConfiguration()
    {
        try
        {
            // Always load global config for comparison/fallback
            _globalConfig = await ConfigRepository.GetGlobalConfigAsync();

            if (IsGlobalView)
            {
                // Editing global config directly
                _config = _globalConfig;
            }
            else
            {
                // Load chat-specific config (which may have UseGlobal flags set)
                var chatConfig = await ConfigRepository.GetByChatIdAsync(ChatId!.Value);
                _config = chatConfig ?? new ContentDetectionConfig();
            }
        }
        catch (Exception ex)
        {
            Snackbar.Add($"Error loading configuration: {ex.Message}", Severity.Error);
            _config = new ContentDetectionConfig();
            _globalConfig = new ContentDetectionConfig();
        }
    }

    public ContentDetectionConfig GetConfig()
    {
        // Ensure global configs always have UseGlobal=true
        if (IsGlobalView)
        {
            _config.OpenAI.UseGlobal = true;
        }

        return _config;
    }

    private async Task LoadPromptVersions()
    {
        // Load prompt versions for the current scope (global or chat-specific)
        long targetChatId = IsGlobalView ? 0 : (ChatId ?? 0);

        try
        {
            _promptVersions = await PromptVersionRepository.GetVersionHistoryByChatIdAsync(targetChatId);
        }
        catch (Exception ex)
        {
            Snackbar.Add($"Error loading prompt versions: {ex.Message}", Severity.Warning);
            _promptVersions = [];
        }
    }

    private async Task OpenPromptBuilder()
    {
        long targetChatId = IsGlobalView ? 0 : (ChatId ?? 0);

        var parameters = new DialogParameters<PromptBuilderDialog>
        {
            { x => x.ChatId, targetChatId }
        };

        var options = new DialogOptions
        {
            MaxWidth = MaxWidth.Medium,
            FullWidth = true,
            CloseOnEscapeKey = true
        };

        var dialog = await DialogService.ShowAsync<PromptBuilderDialog>("AI Prompt Builder", parameters, options);
        var result = await dialog.Result;

        if (result is { Canceled: false, Data: string generatedPrompt })
        {
            try
            {
                var userEmail = await AuthHelper.GetCurrentUserEmailAsync();

                // Save as new version
                var newVersion = await PromptVersionRepository.CreateVersionAsync(
                    targetChatId,
                    generatedPrompt,
                    userEmail,
                    null
                );

                // Update the config to use the new prompt
                var configToUpdate = (IsGlobalView || !_config.OpenAI.UseGlobal) ? _config.OpenAI : _globalConfig.OpenAI;
                configToUpdate.SystemPrompt = generatedPrompt;

                // Reload versions to show the new one
                await LoadPromptVersions();

                Snackbar.Add($"Prompt v{newVersion.Version} created and activated!", Severity.Success);
            }
            catch (Exception ex)
            {
                Snackbar.Add($"Error saving prompt: {ex.Message}", Severity.Error);
            }
        }
    }

    private async Task RestoreVersion(long versionId)
    {
        try
        {
            var restoredVersion = await PromptVersionRepository.RestoreVersionAsync(versionId);

            // Update the config to use the restored prompt
            var configToUpdate = (IsGlobalView || !_config.OpenAI.UseGlobal) ? _config.OpenAI : _globalConfig.OpenAI;
            configToUpdate.SystemPrompt = restoredVersion.PromptText;

            // Reload versions to update UI
            await LoadPromptVersions();

            Snackbar.Add($"Prompt v{restoredVersion.Version} restored and activated!", Severity.Success);
        }
        catch (Exception ex)
        {
            Snackbar.Add($"Error restoring prompt: {ex.Message}", Severity.Error);
        }
    }

    private async Task ViewVersion(PromptVersion version)
    {
        await DialogService.ShowMessageBox(
            $"Prompt Version {version.Version}",
            version.PromptText,
            "Close");
    }

    private async Task OpenImproveDialog(PromptVersion version)
    {
        var parameters = new DialogParameters<PromptImprovementDialog>
        {
            { x => x.CurrentPrompt, version.PromptText }
        };

        var options = new DialogOptions
        {
            MaxWidth = MaxWidth.Medium,
            FullWidth = true,
            CloseOnEscapeKey = true
        };

        var dialog = await DialogService.ShowAsync<PromptImprovementDialog>(
            $"Improve Prompt v{version.Version}",
            parameters,
            options);

        var result = await dialog.Result;

        if (result is { Canceled: false, Data: string improvedPrompt })
        {
            try
            {
                long targetChatId = IsGlobalView ? 0 : (ChatId ?? 0);
                var userEmail = await AuthHelper.GetCurrentUserEmailAsync();

                // Save as new version
                var newVersion = await PromptVersionRepository.CreateVersionAsync(
                    targetChatId,
                    improvedPrompt,
                    userEmail,
                    null
                );

                // Update the config to use the new improved prompt
                var configToUpdate = (IsGlobalView || !_config.OpenAI.UseGlobal) ? _config.OpenAI : _globalConfig.OpenAI;
                configToUpdate.SystemPrompt = improvedPrompt;

                // Reload versions to show the new one
                await LoadPromptVersions();

                Snackbar.Add($"Improved prompt saved as v{newVersion.Version} and activated!", Severity.Success);
            }
            catch (Exception ex)
            {
                Snackbar.Add($"Error saving improved prompt: {ex.Message}", Severity.Error);
            }
        }
    }
}
